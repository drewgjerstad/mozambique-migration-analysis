{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006cfbcf",
   "metadata": {},
   "source": [
    "# Classification Analysis\n",
    "This notebook contains work done for classification analysis on the Mozambique\n",
    "dataset from IPUMS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331debd",
   "metadata": {},
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from src.utils.ipums_extract import load_ipums_from_pkl\n",
    "from src.models.train import train_sklearn_model\n",
    "from src.models.eval import evaluate_sklearn_model\n",
    "from src.models.neural_net import (\n",
    "    train_neural_net,\n",
    "    evaluate_neural_net\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3588dd5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25017ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5929529, 66)\n",
      "(4974569, 66)\n"
     ]
    }
   ],
   "source": [
    "PKL_PATH = Path(r\"data/mozambique.pkl\")\n",
    "mig1_df, mig5_df = load_ipums_from_pkl(PKL_PATH)\n",
    "\n",
    "print(mig1_df.shape)\n",
    "print(mig5_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdee3e0",
   "metadata": {},
   "source": [
    "## Compute Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40ea37",
   "metadata": {},
   "source": [
    "In the cells below, we examine the class distribution for our two response\n",
    "variables. From these results, we can see that we have an extremely unbalanced\n",
    "dataset. Therefore, for the models implemented in Scikit-Learn we will use\n",
    "class weights to automatically balance the classes by assigning lower weights\n",
    "to majority class samples and higher weights to minority class samples. For the\n",
    "neural network, we will employ dropout layers and a weighted loss function to in\n",
    "principle accomplish the same goal. The next cell outlines papers where this is\n",
    "discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c4aad",
   "metadata": {},
   "source": [
    "\"A systematic study of the class imbalance problem in convolutional neural\n",
    "networks\" by Buda et al. (2018)\n",
    "\n",
    "\"Focal Loss for Dense Object Detection\" by Lin et al. (2017)\n",
    "\n",
    "\"Learning from Imbalanced Data\" by He et al. (2009)\n",
    "\n",
    "\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\" by\n",
    "Srivastava et al. (2014)\n",
    "\n",
    "\"Deep Learning for imbalanced multimedia data classification\" by Pouyanfar et\n",
    "al. (2018)\n",
    "\n",
    "\"Class-Balanced Loss Based on Effective Number of Samples\" by Cui et al. (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f58d2899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIGRATE1\n",
      "0    5860462\n",
      "1      69067\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mig1_df['MIGRATE1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2fe0fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIGRATE5\n",
      "0    4746396\n",
      "1     228173\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mig5_df['MIGRATE5'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858b614",
   "metadata": {},
   "source": [
    "## Create Development Splits (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51399706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Hyperparameters\n",
    "SEED = 5523\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "TRAIN_RATIO = 1 - VAL_RATIO - TEST_RATIO\n",
    "assert np.sum([TRAIN_RATIO, VAL_RATIO, TEST_RATIO]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebdac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIG1\n",
    "X1 = mig1_df.drop(columns=['MIGRATE1'], inplace=False, axis=1)\n",
    "y1 = mig1_df['MIGRATE1'].values\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1,\n",
    "                                                        test_size=TEST_RATIO,\n",
    "                                                        random_state=SEED,\n",
    "                                                        stratify=y1)\n",
    "\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train,\n",
    "                                                      test_size=VAL_RATIO,\n",
    "                                                      random_state=SEED,\n",
    "                                                      stratify=y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eaccf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIG5\n",
    "X5 = mig5_df.drop(columns=['MIGRATE5'], inplace=False, axis=1)\n",
    "y5 = mig5_df['MIGRATE5'].values\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5,\n",
    "                                                        test_size=TEST_RATIO,\n",
    "                                                        random_state=SEED,\n",
    "                                                        stratify=y5)\n",
    "\n",
    "X5_train, X5_val, y5_train, y5_val = train_test_split(X5_train, y5_train,\n",
    "                                                      test_size=VAL_RATIO,\n",
    "                                                      random_state=SEED,\n",
    "                                                      stratify=y5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb6308",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "In this section, we apply a Random Forest implemented in Scikit-Learn to\n",
    "classify census samples' migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec462bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Classifiers\n",
    "forest1 = RandomForestClassifier()\n",
    "forest5 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5974913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameter Grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': ['sqrt'],\n",
    "    'class_weight': ['balanced'],\n",
    "    'bootstrap': [True],\n",
    "    'random_state': [SEED]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cbb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG1\n",
    "forest1, forest1_results = train_sklearn_model(\n",
    "    forest1, param_grid, X1_train, y1_train, X1_val, y1_val\n",
    ")\n",
    "\n",
    "forest1_test_results = evaluate_sklearn_model(forest1, X1_test, y1_test)\n",
    "print(f\"\\n{forest1_test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d452bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG5\n",
    "forest5, forest5_results = train_sklearn_model(\n",
    "    forest5, param_grid, X5_train, y5_train, X5_val, y5_val\n",
    ")\n",
    "\n",
    "forest5_test_results = evaluate_sklearn_model(forest5, X5_test, y5_test)\n",
    "print(f\"\\n{forest5_test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c356a",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "In this section, we apply a SVM model implemented in Scikit-Learn to classify\n",
    "census samples' migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53485ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVC\n",
    "svc1 = SVC()\n",
    "svc5 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de1165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameter Grid for SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale'],\n",
    "    'class_weight': ['balanced'],\n",
    "    'random_state': [SEED]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG1\n",
    "svc1, svc1_results = train_sklearn_model(\n",
    "    svc1, param_grid, X1_train, y1_train, X1_val, y1_val\n",
    ")\n",
    "\n",
    "svc1_test_results = evaluate_sklearn_model(svc1, X1_test, y1_test)\n",
    "print(f\"\\n{svc1_test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG5\n",
    "svc5, svc5_results = train_sklearn_model(\n",
    "    svc5, param_grid, X5_train, y5_train, X5_val, y5_val\n",
    ")\n",
    "\n",
    "svc5_test_results = evaluate_sklearn_model(svc5, X5_test, y5_test)\n",
    "print(f\"\\n{svc5_test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332806ef",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "In this section, we apply an artificial neural network implemented in PyTorch to\n",
    "classify census samples' migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG1\n",
    "nn1, nn1_results = train_neural_net(\n",
    "    X1_train, y1_train, X1_val, y1_val,\n",
    "    n_epochs=50,\n",
    "    batch_size=256,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "nn1_test_results = evaluate_neural_net(nn1, X1_test, y1_test)\n",
    "print(f\"\\n{nn1_test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG5\n",
    "nn5, nn5_results = train_neural_net(\n",
    "    X5_train, y5_train, X5_val, y5_val,\n",
    "    n_epochs=50,\n",
    "    batch_size=256,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "nn5_test_results = evaluate_neural_net(nn5, X5_test, y5_test)\n",
    "print(f\"\\n{nn5_test_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
