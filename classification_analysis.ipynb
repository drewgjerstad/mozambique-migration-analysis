{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006cfbcf",
   "metadata": {},
   "source": [
    "# Classification Analysis\n",
    "This notebook contains work done for classification analysis on the Mozambique\n",
    "dataset from IPUMS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331debd",
   "metadata": {},
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895b251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader\n",
    ")\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from src.utils.ipums_extract import load_ipums_from_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3588dd5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25017ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5929529, 66)\n",
      "(4974569, 66)\n"
     ]
    }
   ],
   "source": [
    "PKL_PATH = Path(r\"data/mozambique.pkl\")\n",
    "mig1_df, mig5_df = load_ipums_from_pkl(PKL_PATH)\n",
    "\n",
    "print(mig1_df.shape)\n",
    "print(mig5_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdee3e0",
   "metadata": {},
   "source": [
    "## Compute Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40ea37",
   "metadata": {},
   "source": [
    "In the cells below, we examine the class distribution for our two response\n",
    "variables. From these results, we can see that we have an extremely unbalanced\n",
    "dataset. Therefore, for the models implemented in Scikit-Learn we will use\n",
    "class weights to automatically balance the classes by assigning lower weights\n",
    "to majority class samples and higher weights to minority class samples. For the\n",
    "neural network, we will employ dropout layers and a weighted loss function to in\n",
    "principle accomplish the same goal. The next cell outlines papers where this is\n",
    "discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c4aad",
   "metadata": {},
   "source": [
    "\"A systematic study of the class imbalance problem in convolutional neural\n",
    "networks\" by Buda et al. (2018)\n",
    "\n",
    "\"Focal Loss for Dense Object Detection\" by Lin et al. (2017)\n",
    "\n",
    "\"Learning from Imbalanced Data\" by He et al. (2009)\n",
    "\n",
    "\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\" by\n",
    "Srivastava et al. (2014)\n",
    "\n",
    "\"Deep Learning for imbalanced multimedia data classification\" by Pouyanfar et\n",
    "al. (2018)\n",
    "\n",
    "\"Class-Balanced Loss Based on Effective Number of Samples\" by Cui et al. (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f58d2899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIGRATE1\n",
      "0    5860462\n",
      "1      69067\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mig1_df['MIGRATE1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2fe0fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIGRATE5\n",
      "0    4746396\n",
      "1     228173\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mig5_df['MIGRATE5'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858b614",
   "metadata": {},
   "source": [
    "## Create Development Splits (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51399706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Hyperparameters\n",
    "SEED = 5523\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "TRAIN_RATIO = 1 - VAL_RATIO - TEST_RATIO\n",
    "assert np.sum([TRAIN_RATIO, VAL_RATIO, TEST_RATIO]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebdac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIG1\n",
    "X1 = mig1_df.drop(columns=['MIGRATE1'], inplace=False, axis=1)\n",
    "y1 = mig1_df['MIGRATE1'].values\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1,\n",
    "                                                        test_size=TEST_RATIO,\n",
    "                                                        random_state=SEED,\n",
    "                                                        stratify=y1)\n",
    "\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train,\n",
    "                                                      test_size=VAL_RATIO,\n",
    "                                                      random_state=SEED,\n",
    "                                                      stratify=y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eaccf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIG5\n",
    "X5 = mig5_df.drop(columns=['MIGRATE5'], inplace=False, axis=1)\n",
    "y5 = mig5_df['MIGRATE5'].values\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5,\n",
    "                                                        test_size=TEST_RATIO,\n",
    "                                                        random_state=SEED,\n",
    "                                                        stratify=y5)\n",
    "\n",
    "X5_train, X5_val, y5_train, y5_val = train_test_split(X5_train, y5_train,\n",
    "                                                      test_size=VAL_RATIO,\n",
    "                                                      random_state=SEED,\n",
    "                                                      stratify=y5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb6308",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "In this section, we define a random forest using Scikit-Learn to be applied for\n",
    "classifying census samples' migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52764b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Train Random Forest classifier with class weights for handling the\n",
    "    imbalanced dataset and with hyperparameter optimization.\"\"\"\n",
    "\n",
    "    # Define Parameter Grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_split': [5, 10],\n",
    "        'min_samples_leaf': [2, 4],\n",
    "        'max_features': ['sqrt'],\n",
    "        'class_weight': ['balanced'],\n",
    "        'bootstrap': [True],\n",
    "        'random_state': [SEED]\n",
    "    }\n",
    "\n",
    "    # Define Base Model\n",
    "    forest = RandomForestClassifier()\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=forest,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Print Best Found Hyperparameters\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    for param, val in grid_search.best_params_.items():\n",
    "        print(f\"{param}: {val}\")\n",
    "    print(f\"Best CV F1 Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Evaluate Using Validation Set\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    y_val_prob = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'precision': precision_score(y_val, y_val_pred, average='weighted'),\n",
    "        'recall': recall_score(y_val, y_val_pred, average='weighted'),\n",
    "        'f1': f1_score(y_val, y_val_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y_val, y_val_prob)\n",
    "    }\n",
    "\n",
    "    # Print Validation Set Performance\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    for metric, val in metrics.items():\n",
    "        print(f\"{metric}: {val:.4f}\")\n",
    "    \n",
    "    # Print Feature Importance Analysis\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(\"T\\nop 10 Most Important Features\")\n",
    "        print(feature_importance.head(10))\n",
    "    \n",
    "    return best_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f3fcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_forest(model, X_test, y_test):\n",
    "    \"\"\"Evaluate trained Random Forest on test set.\"\"\"\n",
    "\n",
    "    # Compute Predictions\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute Metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
    "        'f1': f1_score(y_test, y_test_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y_test, y_test_prob)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cbb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG1\n",
    "forest1, forest1_results = train_random_forest(\n",
    "    X1_train, y1_train, X1_val, y1_val\n",
    ")\n",
    "\n",
    "forest1_test_results = evaluate_random_forest(forest1, X1_test, y1_test)\n",
    "print(f\"\\n{forest1_test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d452bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG5\n",
    "forest5, forest5_results = train_random_forest(\n",
    "    X5_train, y5_train, X5_val, y5_val\n",
    ")\n",
    "\n",
    "forest5_test_results = evaluate_random_forest(forest5, X5_test, y5_test)\n",
    "print(f\"\\n{forest5_test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c356a",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "In this section, we define a support vector machine model using Scikit-Learn to\n",
    "be applied for classifying census samples' migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c19aea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svc(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Train Support Vector classifier with class weights for handling the\n",
    "    imbalanced dataset and with hyperparameter optimization.\"\"\"\n",
    "\n",
    "    # Define Parameter Grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale'],\n",
    "        'class_weight': ['balanced'],\n",
    "        'random_state': [SEED]\n",
    "    }\n",
    "\n",
    "    # Define Base Model\n",
    "    svc = SVC(probability=True, max_iter=1000)\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=svc,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Print Best Found Hyperparameters\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    for param, val in grid_search.best_params_.items():\n",
    "        print(f\"{param}: {val}\")\n",
    "    print(f\"Best CV F1 Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Evaluate Using Validation Set\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    y_val_prob = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'precision': precision_score(y_val, y_val_pred, average='weighted'),\n",
    "        'recall': recall_score(y_val, y_val_pred, average='weighted'),\n",
    "        'f1': f1_score(y_val, y_val_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y_val, y_val_prob)\n",
    "    }\n",
    "\n",
    "    # Print Validation Set Performance\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    for metric, val in metrics.items():\n",
    "        print(f\"{metric}: {val:.4f}\")\n",
    "    \n",
    "    # Print Feature Importance Analysis\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(\"T\\nop 10 Most Important Features\")\n",
    "        print(feature_importance.head(10))\n",
    "    \n",
    "    return best_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8f4362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svc(model, X_test, y_test):\n",
    "    \"\"\"Evaluate trained Random Forest on test set.\"\"\"\n",
    "\n",
    "    # Compute Predictions\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute Metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
    "        'f1': f1_score(y_test, y_test_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y_test, y_test_prob)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG1\n",
    "svc1, svc1_results = train_svc(\n",
    "    X1_train, y1_train, X1_val, y1_val\n",
    ")\n",
    "\n",
    "svc1_test_results = evaluate_svc(svc1, X1_test, y1_test)\n",
    "print(f\"\\n{svc1_test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG5\n",
    "svc5, svc5_results = train_svc(\n",
    "    X5_train, y5_train, X5_val, y5_val\n",
    ")\n",
    "\n",
    "svc5_test_results = evaluate_svc(svc5, X5_test, y5_test)\n",
    "print(f\"\\n{svc5_test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332806ef",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "In this section, we define a artificial neural network using PyTorch to be\n",
    "applied for classifying census samples' migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd2429ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network with imbalanced data handling.\n",
    "     * Dropout (default=0.3) prevents overfitting the majority class\n",
    "     * Batch normalization stabilizes training with imbalanced batches\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64],\n",
    "                 num_classes=2, dropout=0.3):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, num_classes))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f7d9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(y):\n",
    "    \"\"\"Compute balanced class weights for loss function.\"\"\"\n",
    "    classes = np.unique(y)\n",
    "    class_counts = np.bincount(y)\n",
    "    weights = len(y) / (len(classes) * class_counts)\n",
    "    return torch.FloatTensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2246d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Custom Dataset wrapper for migration data.\"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X.values)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9aa190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_net(X_train, y_train, X_val, y_val, n_epochs=50,\n",
    "                     batch_size=256, learning_rate=0.001):\n",
    "    \"\"\"Train neural network with class-weighted loss.\"\"\"\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weights(y_train)\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    val_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize neural net\n",
    "    model = NeuralNetwork(\n",
    "        input_dim=X_train.shape[1],\n",
    "        hidden_dims=[256, 128, 64],\n",
    "        dropout=0.3\n",
    "    ).to(device)\n",
    "\n",
    "    # Define loss function, optimizer, learning rate schedule\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    # Training Loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 10\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_f1': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation performance\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(batch_y.cpu().numpy())\n",
    "        \n",
    "        # Compute metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_f1'].append(val_f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f},\"\n",
    "              f\" Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Add early stopping (prevent overfitting of majority class)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8556433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_neural_network(model, X_test, y_test):\n",
    "    \"\"\"Evaluate trained neural network.\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Test dataset and loader\n",
    "    test_dataset = CustomDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    # Prediction storage\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(batch_y.numpy())\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, average='weighted'),\n",
    "        'recall': recall_score(all_labels, all_preds, average='weighted'),\n",
    "        'f1': f1_score(all_labels, all_preds, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(all_labels, all_preds)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG1\n",
    "nn1, nn1_results = train_neural_net(\n",
    "    X1_train, y1_train, X1_val, y1_val,\n",
    "    n_epochs=50,\n",
    "    batch_size=256,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "nn1_test_results = evaluate_neural_network(nn1, X1_test, y1_test)\n",
    "print(f\"\\n{nn1_test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate for MIG5\n",
    "nn5, nn5_results = train_neural_net(\n",
    "    X5_train, y5_train, X5_val, y5_val,\n",
    "    n_epochs=50,\n",
    "    batch_size=256,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "nn5_test_results = evaluate_neural_network(nn5, X5_test, y5_test)\n",
    "print(f\"\\n{nn5_test_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
